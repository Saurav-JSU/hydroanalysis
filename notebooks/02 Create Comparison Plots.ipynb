{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precipitation Data Analysis and Comparison\n",
    "\n",
    "This notebook processes and compares precipitation data from multiple sources:\n",
    "- High Resolution precipitation data\n",
    "- ERA5 reanalysis data\n",
    "- GSMaP satellite data\n",
    "- IMERG satellite data\n",
    "- Observed precipitation data\n",
    "\n",
    "We'll process the high-resolution data to match the DHM-style daily precipitation format, then compare all datasets visually and statistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configure visualization settings for publication quality\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Available Floods\n",
    "\n",
    "First, let's identify all the available flood directories in the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all flood directories\n",
    "flood_dirs = sorted(glob(\"../results/floods/flood_*\"))\n",
    "flood_names = [os.path.basename(d) for d in flood_dirs]\n",
    "\n",
    "print(f\"Found {len(flood_names)} flood events: {flood_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process High-Resolution Data to Daily Format\n",
    "\n",
    "This function processes high-resolution precipitation data to conform to DHM-style daily format by:\n",
    "1. Shifting timestamps by -8 hours and 45 minutes\n",
    "2. Aggregating to daily values\n",
    "3. Saving the processed data to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_highres_data(flood_name):\n",
    "    \"\"\"Process high-resolution precipitation data to daily format with DHM-style shifting\"\"\"\n",
    "    # File paths\n",
    "    highres_csv = f\"../results/floods/{flood_name}/highres/high_resolution_precipitation.csv\"\n",
    "    output_csv = f\"../results/floods/{flood_name}/highres/high_resolution_precipitation_daily.csv\"\n",
    "    \n",
    "    # Check if highres data exists\n",
    "    if not os.path.exists(highres_csv):\n",
    "        print(f\"⚠️ High-resolution data not found for {flood_name}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Processing high-resolution data for {flood_name}...\")\n",
    "    \n",
    "    # Load high-resolution precipitation data\n",
    "    highres = pd.read_csv(highres_csv)\n",
    "    \n",
    "    # Convert datetime column to datetime format\n",
    "    highres[\"datetime\"] = pd.to_datetime(highres[\"datetime\"])\n",
    "    \n",
    "    # Apply DHM-style daily shifting (shift timestamp by -8 hours and 45 minutes)\n",
    "    highres[\"shifted_time\"] = highres[\"datetime\"] - pd.Timedelta(hours=8, minutes=45)\n",
    "    \n",
    "    # Create date column based on shifted timestamp\n",
    "    highres[\"date\"] = (highres[\"shifted_time\"].dt.normalize() + pd.Timedelta(days=1))\n",
    "    \n",
    "    # Group by date and sum numeric columns\n",
    "    numeric_cols = highres.select_dtypes(include='number').columns\n",
    "    highres_daily = highres.groupby(\"date\")[numeric_cols].sum()\n",
    "    \n",
    "    # Sort by date and reset index\n",
    "    highres_daily = highres_daily.sort_index()\n",
    "    highres_daily = highres_daily.reset_index()\n",
    "    \n",
    "    # Save the processed data\n",
    "    highres_daily.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"✅ High-resolution data converted to DHM-style daily precipitation and saved to: {output_csv}\")\n",
    "    return output_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Precipitation Data Sources\n",
    "\n",
    "This function loads and compares precipitation data from different sources:\n",
    "- High-resolution precipitation data\n",
    "- ERA5 reanalysis\n",
    "- GSMaP satellite data\n",
    "- IMERG satellite data\n",
    "- Observed precipitation data\n",
    "\n",
    "It generates publication-quality comparison plots for each common station and includes statistical metrics (RMSE and R²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_precipitation_data(flood_name):\n",
    "    \"\"\"Compare precipitation data from different sources and generate publication-quality plots\"\"\"\n",
    "    # Process high-resolution data if it hasn't been processed yet\n",
    "    highres_path = f\"../results/floods/{flood_name}/highres/high_resolution_precipitation_daily.csv\"\n",
    "    if not os.path.exists(highres_path):\n",
    "        highres_path = process_highres_data(flood_name)\n",
    "        if highres_path is None:\n",
    "            return\n",
    "    \n",
    "    # Define file paths\n",
    "    era5_path = f\"../results/floods/{flood_name}/gee_era5/daily_precipitation.csv\"\n",
    "    gsmap_path = f\"../results/floods/{flood_name}/gee_gsmap/daily_precipitation.csv\"\n",
    "    imerg_path = f\"../results/floods/{flood_name}/gee_imerg/daily_precipitation.csv\"\n",
    "    observed_path = \"../data/filtered_observed_precip.xlsx\"\n",
    "    \n",
    "    # Create output directory - UPDATED PATH as requested\n",
    "    output_dir = f\"../results/floods/{flood_name}/Final Comparison\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if required files exist\n",
    "    missing_files = []\n",
    "    for path, name in [(era5_path, \"ERA5\"), (gsmap_path, \"GSMaP\"), \n",
    "                       (imerg_path, \"IMERG\"), (observed_path, \"Observed\")]:\n",
    "        if not os.path.exists(path):\n",
    "            missing_files.append(name)\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"⚠️ Missing data files for {flood_name}: {', '.join(missing_files)}\")\n",
    "        if \"Observed\" in missing_files:\n",
    "            print(\"⚠️ Observed data is required for comparison. Aborting.\")\n",
    "            return\n",
    "    \n",
    "    print(f\"Comparing precipitation data for {flood_name}...\")\n",
    "    \n",
    "    # Load data\n",
    "    datasets = {}\n",
    "    try:\n",
    "        datasets[\"highres\"] = pd.read_csv(highres_path)\n",
    "        if os.path.exists(era5_path):\n",
    "            datasets[\"era5\"] = pd.read_csv(era5_path)\n",
    "        if os.path.exists(gsmap_path):\n",
    "            datasets[\"gsmap\"] = pd.read_csv(gsmap_path)\n",
    "        if os.path.exists(imerg_path):\n",
    "            datasets[\"imerg\"] = pd.read_csv(imerg_path)\n",
    "        datasets[\"observed\"] = pd.read_excel(observed_path)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error loading data: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Parse and set date columns\n",
    "    try:\n",
    "        datasets[\"highres\"][\"date\"] = pd.to_datetime(datasets[\"highres\"][\"date\"])\n",
    "        datasets[\"highres\"] = datasets[\"highres\"].set_index(\"date\")\n",
    "        \n",
    "        if \"era5\" in datasets:\n",
    "            datasets[\"era5\"][\"Date\"] = pd.to_datetime(datasets[\"era5\"][\"Date\"])\n",
    "            datasets[\"era5\"] = datasets[\"era5\"].set_index(\"Date\")\n",
    "        \n",
    "        if \"gsmap\" in datasets:\n",
    "            datasets[\"gsmap\"][\"Date\"] = pd.to_datetime(datasets[\"gsmap\"][\"Date\"])\n",
    "            datasets[\"gsmap\"] = datasets[\"gsmap\"].set_index(\"Date\")\n",
    "        \n",
    "        if \"imerg\" in datasets:\n",
    "            datasets[\"imerg\"][\"Date\"] = pd.to_datetime(datasets[\"imerg\"][\"Date\"])\n",
    "            datasets[\"imerg\"] = datasets[\"imerg\"].set_index(\"Date\")\n",
    "        \n",
    "        # Process observed data\n",
    "        datasets[\"observed\"][\"date\"] = pd.to_datetime(datasets[\"observed\"][[\"year\", \"month\", \"days\"]]).dt.normalize()\n",
    "        datasets[\"observed\"] = datasets[\"observed\"].set_index(\"date\").drop(columns=[\"year\", \"month\", \"days\"])\n",
    "        datasets[\"observed\"].columns = datasets[\"observed\"].columns.astype(str)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing dates: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Align dates based on highres dates\n",
    "    daily_dates = datasets[\"highres\"].index.normalize()\n",
    "    \n",
    "    def align_dates(df, valid_dates):\n",
    "        df.index = pd.to_datetime(df.index).normalize()\n",
    "        return df.loc[df.index.isin(valid_dates)]\n",
    "    \n",
    "    aligned_data = {}\n",
    "    aligned_data[\"highres\"] = align_dates(datasets[\"highres\"], daily_dates)\n",
    "    \n",
    "    if \"era5\" in datasets:\n",
    "        aligned_data[\"era5\"] = align_dates(datasets[\"era5\"], daily_dates)\n",
    "    if \"gsmap\" in datasets:\n",
    "        aligned_data[\"gsmap\"] = align_dates(datasets[\"gsmap\"], daily_dates)\n",
    "    if \"imerg\" in datasets:\n",
    "        aligned_data[\"imerg\"] = align_dates(datasets[\"imerg\"], daily_dates)\n",
    "    \n",
    "    aligned_data[\"observed\"] = datasets[\"observed\"].loc[datasets[\"observed\"].index.isin(daily_dates)]\n",
    "    \n",
    "    # Find common stations\n",
    "    station_sets = []\n",
    "    \n",
    "    # Extract station IDs from column names for each dataset\n",
    "    hr_stations = [col.split(\"_\")[-1] for col in aligned_data[\"highres\"].columns]\n",
    "    station_sets.append(set(hr_stations))\n",
    "    \n",
    "    if \"era5\" in aligned_data:\n",
    "        era5_stations = [col.split(\"_\")[-1] for col in aligned_data[\"era5\"].columns]\n",
    "        station_sets.append(set(era5_stations))\n",
    "    \n",
    "    if \"gsmap\" in aligned_data:\n",
    "        gsmap_stations = [col.split(\"_\")[-1] for col in aligned_data[\"gsmap\"].columns]\n",
    "        station_sets.append(set(gsmap_stations))\n",
    "        \n",
    "    if \"imerg\" in aligned_data:\n",
    "        imerg_stations = [col.split(\"_\")[-1] for col in aligned_data[\"imerg\"].columns]\n",
    "        station_sets.append(set(imerg_stations))\n",
    "    \n",
    "    observed_stations = list(aligned_data[\"observed\"].columns)\n",
    "    station_sets.append(set(observed_stations))\n",
    "    \n",
    "    # Find common stations across all datasets\n",
    "    common_stations = sorted(set.intersection(*station_sets))\n",
    "    \n",
    "    print(f\"✅ Found {len(common_stations)} common stations for comparison: {common_stations}\")\n",
    "    \n",
    "    # Prepare statistics table\n",
    "    stats_table = pd.DataFrame(\n",
    "        index=[\"ERA5\", \"GSMaP\", \"HighRes\", \"IMERG\"],\n",
    "        columns=[\"RMSE\", \"R2\"]\n",
    "    )\n",
    "    \n",
    "    # Initialized aggregated statistics\n",
    "    aggregated_stats = {\n",
    "        \"ERA5\": {\"rmse\": [], \"r2\": []},\n",
    "        \"GSMaP\": {\"rmse\": [], \"r2\": []},\n",
    "        \"HighRes\": {\"rmse\": [], \"r2\": []},\n",
    "        \"IMERG\": {\"rmse\": [], \"r2\": []}\n",
    "    }\n",
    "    \n",
    "    # Create plots for each station\n",
    "    for sid in common_stations:\n",
    "        colname = f\"Station_{sid}\"\n",
    "        \n",
    "        try:\n",
    "            # Create figure and axes with seaborn style\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            \n",
    "            # Dictionary to collect data for statistics\n",
    "            station_data = {}\n",
    "            \n",
    "            # Get observed data for this station\n",
    "            if sid in aligned_data[\"observed\"].columns and aligned_data[\"observed\"][sid].notna().any():\n",
    "                observed_data = aligned_data[\"observed\"][sid]\n",
    "                sns.lineplot(x=aligned_data[\"observed\"].index, y=observed_data, \n",
    "                           label=\"Observed\", linestyle='--', linewidth=2.5, color='black', ax=ax)\n",
    "                station_data[\"Observed\"] = observed_data\n",
    "            else:\n",
    "                print(f\"⚠️ No observed data for station {sid}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Plot each dataset if available with enhanced styling\n",
    "            datasets_to_plot = [\n",
    "                (\"highres\", \"HighRes\", \"#1f77b4\"),  # More vibrant blue\n",
    "                (\"era5\", \"ERA5\", \"#d62728\"),        # More vibrant red\n",
    "                (\"gsmap\", \"GSMaP\", \"#2ca02c\"),      # More vibrant green\n",
    "                (\"imerg\", \"IMERG\", \"#9467bd\")       # More vibrant purple\n",
    "            ]\n",
    "            \n",
    "            for data_key, label, color in datasets_to_plot:\n",
    "                if data_key in aligned_data and colname in aligned_data[data_key].columns and aligned_data[data_key][colname].notna().any():\n",
    "                    sns.lineplot(x=aligned_data[data_key].index, y=aligned_data[data_key][colname], \n",
    "                               label=label, linewidth=2, color=color, ax=ax)\n",
    "                    station_data[label] = aligned_data[data_key][colname]\n",
    "            \n",
    "            # Calculate statistics for this station\n",
    "            station_stats = {}\n",
    "            for label, data in station_data.items():\n",
    "                if label != \"Observed\" and \"Observed\" in station_data:\n",
    "                    # Align the data\n",
    "                    model_data = data.reindex(station_data[\"Observed\"].index)\n",
    "                    observed_aligned = station_data[\"Observed\"].reindex(model_data.index)\n",
    "                    \n",
    "                    # Remove NaN values\n",
    "                    valid_idx = ~(model_data.isna() | observed_aligned.isna())\n",
    "                    if valid_idx.sum() > 0:\n",
    "                        model_clean = model_data[valid_idx]\n",
    "                        observed_clean = observed_aligned[valid_idx]\n",
    "                        \n",
    "                        # Calculate statistics\n",
    "                        rmse = np.sqrt(mean_squared_error(observed_clean, model_clean))\n",
    "                        r2 = r2_score(observed_clean, model_clean)\n",
    "                        \n",
    "                        station_stats[label] = {\"RMSE\": rmse, \"R2\": r2}\n",
    "                        \n",
    "                        # Add to aggregated statistics\n",
    "                        aggregated_stats[label][\"rmse\"].append(rmse)\n",
    "                        aggregated_stats[label][\"r2\"].append(r2)\n",
    "            \n",
    "            # Add statistics table to plot using a more elegant approach\n",
    "            if station_stats:\n",
    "                # Create a styled statistics table\n",
    "                table_data = []\n",
    "                for model, metrics in station_stats.items():\n",
    "                    table_data.append([model, f\"{metrics['RMSE']:.2f}\", f\"{metrics['R2']:.2f}\"])\n",
    "                \n",
    "                # Create the table as an inset\n",
    "                table_ax = fig.add_axes([0.68, 0.68, 0.27, 0.20], frame_on=True)\n",
    "                table_ax.axis('off')\n",
    "                table = table_ax.table(\n",
    "                    cellText=table_data,\n",
    "                    colLabels=[\"Model\", \"RMSE\", \"R²\"],\n",
    "                    loc='center',\n",
    "                    cellLoc='center',\n",
    "                    bbox=[0, 0, 1, 1]\n",
    "                )\n",
    "                table.auto_set_font_size(False)\n",
    "                table.set_fontsize(10)\n",
    "                table.scale(1, 1.5)\n",
    "                \n",
    "                # Style the table\n",
    "                for (row, col), cell in table.get_celld().items():\n",
    "                    if row == 0:  # Header row\n",
    "                        cell.set_facecolor('#4472C4')\n",
    "                        cell.set_text_props(color='white', fontweight='bold')\n",
    "                    elif col == 0:  # Model names column\n",
    "                        cell.set_text_props(fontweight='bold')\n",
    "                    \n",
    "                    # Add light alternating colors\n",
    "                    if row > 0 and row % 2 == 0:\n",
    "                        cell.set_facecolor('#E6F0FF')\n",
    "            \n",
    "            # Add title and labels with enhanced styling\n",
    "            ax.set_title(f\"Daily Precipitation Comparison - Station {sid} ({flood_name})\", \n",
    "                       fontweight='bold', pad=20)\n",
    "            ax.set_xlabel(\"Date\", fontweight='bold')\n",
    "            ax.set_ylabel(\"Precipitation (mm)\", fontweight='bold')\n",
    "            \n",
    "            # Enhance legend\n",
    "            leg = ax.legend(\n",
    "                title=\"Data Sources\",\n",
    "                loc='upper left',           # top-left inside the axes\n",
    "                frameon=True,\n",
    "                fancybox=True,\n",
    "                framealpha=0.9,\n",
    "                facecolor='white',\n",
    "                edgecolor='gray'\n",
    "            )\n",
    "            leg.get_title().set_fontweight('bold')\n",
    "\n",
    "\n",
    "            \n",
    "            # Enhance grid\n",
    "            ax.grid(True, linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Improve date formatting\n",
    "            fig.autofmt_xdate()\n",
    "            \n",
    "            # Add a subtle border around the plot\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_color('gray')\n",
    "                spine.set_linewidth(0.5)\n",
    "                \n",
    "            # Remove tight_layout and instead use constrained_layout\n",
    "            fig.subplots_adjust(left=0.1, right=0.95, top=0.9, bottom=0.1)\n",
    "\n",
    "\n",
    "            outpath = os.path.join(output_dir, f\"station_{sid}_comparison.png\")\n",
    "            plt.savefig(outpath, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"✅ Created comparison plot for station {sid}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipped station {sid} due to error: {e}\")\n",
    "    \n",
    "    # Calculate aggregated statistics\n",
    "    for model in aggregated_stats:\n",
    "        if aggregated_stats[model][\"rmse\"]:\n",
    "            stats_table.loc[model, \"RMSE\"] = np.mean(aggregated_stats[model][\"rmse\"])\n",
    "            stats_table.loc[model, \"R2\"] = np.mean(aggregated_stats[model][\"r2\"])\n",
    "    \n",
    "    # Save aggregated statistics\n",
    "    stats_path = os.path.join(output_dir, \"aggregated_statistics.csv\")\n",
    "    stats_table.to_csv(stats_path)\n",
    "    \n",
    "    print(f\"\\n✅ Aggregated statistics across all stations:\")\n",
    "    print(stats_table)\n",
    "    \n",
    "    return stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Flood Selection\n",
    "\n",
    "Select which flood event to analyze using the dropdown menu below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dropdown widget for flood selection\n",
    "def analyze_flood(flood_name):\n",
    "    print(f\"\\n===== Analyzing {flood_name} =====\\n\")\n",
    "    stats = compare_precipitation_data(flood_name)\n",
    "    print(f\"\\n===== Completed analysis for {flood_name} =====\\n\")\n",
    "    return stats\n",
    "\n",
    "# Interactive dropdown\n",
    "if flood_names:\n",
    "    interact(analyze_flood, flood_name=widgets.Dropdown(options=flood_names, description='Flood:'))\n",
    "else:\n",
    "    print(\"No flood directories found in ../results/floods/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze All Floods\n",
    "\n",
    "Run this cell to analyze all available flood events and generate a summary of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_floods():\n",
    "    \"\"\"Run analysis on all flood events and compile statistics\"\"\"\n",
    "    all_stats = {}\n",
    "    \n",
    "    for flood_name in flood_names:\n",
    "        print(f\"\\n===== Analyzing {flood_name} =====\\n\")\n",
    "        stats = compare_precipitation_data(flood_name)\n",
    "        if stats is not None:\n",
    "            all_stats[flood_name] = stats\n",
    "    \n",
    "    if all_stats:\n",
    "        # Create summary table\n",
    "        summary = pd.DataFrame(\n",
    "            index=pd.MultiIndex.from_product(\n",
    "                [list(all_stats.keys()), [\"ERA5\", \"GSMaP\", \"HighRes\", \"IMERG\"]],\n",
    "                names=[\"Flood\", \"Model\"]\n",
    "            ),\n",
    "            columns=[\"RMSE\", \"R2\"]\n",
    "        )\n",
    "        \n",
    "        # Fill summary table\n",
    "        for flood, stats in all_stats.items():\n",
    "            for model in stats.index:\n",
    "                summary.loc[(flood, model), \"RMSE\"] = stats.loc[model, \"RMSE\"]\n",
    "                summary.loc[(flood, model), \"R2\"] = stats.loc[model, \"R2\"]\n",
    "        \n",
    "        # Save summary\n",
    "        summary.to_csv(\"precipitation_comparison_summary.csv\")\n",
    "        \n",
    "        print(\"\\n===== Summary of All Floods =====\\n\")\n",
    "        print(summary)\n",
    "        \n",
    "        # Create comparison plots with publication quality\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "        \n",
    "        # RMSE comparison\n",
    "        summary_pivot = summary.reset_index().pivot(index=\"Flood\", columns=\"Model\", values=\"RMSE\")\n",
    "        \n",
    "        # Use seaborn's color palette\n",
    "        colors = sns.color_palette(\"muted\", n_colors=len(summary_pivot.columns))\n",
    "        \n",
    "        # Plot with enhanced styling\n",
    "        summary_pivot.plot(kind=\"bar\", ax=ax1, color=colors, width=0.8, edgecolor='black', linewidth=0.6)\n",
    "        ax1.set_title(\"RMSE Comparison Across Flood Events\", fontweight='bold', fontsize=16)\n",
    "        ax1.set_ylabel(\"RMSE (mm)\", fontweight='bold', fontsize=14)\n",
    "        ax1.set_xlabel(\"\")  # Remove x-label on top plot\n",
    "        ax1.grid(axis=\"y\", linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for container in ax1.containers:\n",
    "            ax1.bar_label(container, fmt='%.2f', fontsize=8, padding=3)\n",
    "        \n",
    "        # Enhance legend\n",
    "        leg1 = ax1.legend(title=\"Precipitation Products\", frameon=True, \n",
    "                        fancybox=True, framealpha=0.9, facecolor='white', \n",
    "                        edgecolor='gray', loc='upper right')\n",
    "        leg1.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # R2 comparison with enhanced styling\n",
    "        r2_pivot = summary.reset_index().pivot(index=\"Flood\", columns=\"Model\", values=\"R2\")\n",
    "        r2_pivot.plot(kind=\"bar\", ax=ax2, color=colors, width=0.8, edgecolor='black', linewidth=0.6)\n",
    "        ax2.set_title(\"R² Comparison Across Flood Events\", fontweight='bold', fontsize=16)\n",
    "        ax2.set_ylabel(\"R² Value\", fontweight='bold', fontsize=14)\n",
    "        ax2.set_xlabel(\"Flood Event\", fontweight='bold', fontsize=14)\n",
    "        ax2.grid(axis=\"y\", linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for container in ax2.containers:\n",
    "            ax2.bar_label(container, fmt='%.2f', fontsize=8, padding=3)\n",
    "        \n",
    "        # Enhance legend\n",
    "        leg2 = ax2.legend(title=\"Precipitation Products\", frameon=True, \n",
    "                        fancybox=True, framealpha=0.9, facecolor='white', \n",
    "                        edgecolor='gray', loc='upper right')\n",
    "        leg2.get_title().set_fontweight('bold')\n",
    "        \n",
    "        # Add subtle border around the plots\n",
    "        for ax in [ax1, ax2]:\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_color('gray')\n",
    "                spine.set_linewidth(0.5)\n",
    "        \n",
    "        # Add a title for the entire figure\n",
    "        fig.suptitle(\"Comparison of Precipitation Products Across Flood Events\", \n",
    "                   fontsize=18, fontweight='bold', y=0.98)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust for the suptitle\n",
    "        plt.savefig(\"precipitation_model_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        return summary\n",
    "    else:\n",
    "        print(\"No statistics available for summary.\")\n",
    "        return None\n",
    "\n",
    "# Run analysis on all floods\n",
    "# analyze_all_floods()  # Uncomment to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook provides a comprehensive analysis of precipitation data from multiple sources, comparing them against observed data for multiple flood events.\n",
    "\n",
    "Key findings:\n",
    "1. The statistical metrics (RMSE and R²) help quantify the accuracy of each precipitation product\n",
    "2. Visualizations show temporal patterns and differences between precipitation sources\n",
    "3. The analysis can be run for individual flood events or across all available flood data\n",
    "\n",
    "To expand this analysis, you could consider:\n",
    "- Adding more statistical measures (bias, correlation coefficient)\n",
    "- Creating spatial visualizations of precipitation patterns\n",
    "- Analyzing lag effects between precipitation and flood events"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
